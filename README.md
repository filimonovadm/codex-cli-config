# Конфигурация для OpenAI Codex CLI

Этот репозиторий содержит файл конфигурации `config.toml` для инструмента командной строки [OpenAI Codex](https://github.com/openai/codex).
Это мой рабочий конфиг, который я сделал в целях экономии токенов и ответов без воды.

## Настройка модели

Поле `model` в `config.toml` определяет, какой движок будет использовать Codex по умолчанию. Поменять модель можно тремя способами:

- правкой `model = "..."` в `config.toml`;
- запуском разовой сессии с флагом `codex -c model="..."`;
- созданием профиля в конфиге и последующим `codex --profile my-profile`.

## Доступные модели и сценарии использования

| Назначение | Модель | Что получает девопс инженер |
| --- | --- | --- |
| Ежедневные рабочие сессии, правка IaC, Shell/Go/Python | `gpt-5.1-codex`, `gpt-5-codex` | Оптимизированы под код, знают свежий синтаксис и дают развёрнутые шаги |
| Глубокие объяснения, дизайн архитектуры, сложные RFC | `gpt-5.1`, `gpt-5-pro` | Максимум reasoning, помогают в анализе систем и выборе подходов |
| Быстрые короткие ответы, генерация скриптов на лету | `gpt-5-mini`, `gpt-5-nano` | Лёгкие модели, экономят токены и реагируют быстрее |
| Инциденты, продакшен отладка, анализ логов в реальном времени | `gpt-4o`, `gpt-4.1` | Хорошо держат контекст свежих логов и дают структурированные планы действий |
| Интерактивные демо, стриминг подсказок во время презентаций | `gpt-4o-realtime-preview`, `gpt-realtime` | Потоковые модели с минимальной задержкой |
| Поиск по документации и инфраструктурным артефактам | `gpt-5-search-api`, `gpt-4o-mini-search-preview` | Специализированы под retrieval, хорошо ранжируют результаты |
| Генерация постов/объявлений, описаний сервисов | `gpt-4.1-mini`, `gpt-5-mini` | Умеренно креативные ответы без излишней "художественности" |
| Голосовые обзвоны, текст в речь | `tts-1`, `tts-1-hd`, `gpt-4o-mini-tts` | Подготовка аудио-инструкций для on-call команд |
| Фото/диаграммы для документации | `dall-e-3`, `gpt-image-1` | Создание схем и иллюстраций для runbook'ов |

> Примечание: список моделей зависит от вашей учётки. Перед использованием новой модели проверьте доступ через `openai api models.list`.

## Советы по выбору модели

- Долгие ревью Terraform/Ansible лучше делать на `gpt-5.1-codex`: он точнее в синтаксисе и комментирует изменения строчка за строчкой.
- Для RCA инцидентов удобно переключать профиль на `gpt-5-pro`: повышенный reasoning помогает разложить цепочки событий.
- Если нужно просто быстро подсказать команду или one-liner, стартуйте с `gpt-5-nano`, а для серьёзной задачи в той же сессии переключайтесь на более мощную модель.
- Потоковые модели (`gpt-4o-realtime-preview`) полезны на дежурстве: можно диктовать логи и мгновенно получать гипотезы.

## Как переключать модель на лету

```bash
# Разовая сессия с моделью gpt-5-pro
codex -c model="gpt-5-pro"

# Профиль в конфиге
[profiles.production-review]
model = "gpt-5.1-codex"
model_reasoning_effort = "high"

# Запуск с профилем
codex --profile production-review
```

Не забудьте держать `approval_policy = "untrusted"`, если хотите, чтобы агент спрашивал подтверждение перед изменениями в инфраструктурных репозиториях.
